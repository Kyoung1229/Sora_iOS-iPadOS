import Foundation
import UIKit
import Combine
import SwiftData

@MainActor
public final class ChatService: ObservableObject {
    // MARK: - Published Properties
    @Published public var lastStreamingText: String = ""
    @Published public var apiLogs: [String] = []
    @Published public var isProcessing: Bool = false
    
    // MARK: - API ÏÑ§Ï†ï
    public var apiKey: String = ""
    
    // MARK: - ÏΩúÎ∞± Ìï®Ïàò
    var onMessagesUpdated: (([MessageItem]) -> Void)?
    
    // MARK: - Internal Clients & History
    private var history: ChatHistoryManager?
    private var geminiAPI = GeminiAPI()
    private var openaiAPI = OpenAIAPI()
    
    // MARK: - ModelContext & Current Conversation
    private var modelContext: ModelContext
    private var currentConversation: SoraConversationsDatabase?
    private var conversationId: String = ""
    private var currentModel: String = "gemini-pro"
    private var currentMessages: [MessageItem] = []
    
    // MARK: - Ï¥àÍ∏∞Ìôî
    public init(modelContext: ModelContext) {
        self.modelContext = modelContext
        log("ChatService initialized with ModelContext.")
    }
    
    // MARK: - API Ï¥àÍ∏∞Ìôî
    public func initialize() {
        if !apiKey.isEmpty {
            var gemini = self.geminiAPI
            gemini.setApiKey(apiKey)
            self.geminiAPI = gemini
            
            var openai = self.openaiAPI
            openai.setApiKey(apiKey)
            self.openaiAPI = openai
            
            log("API ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏Í∞Ä Ï¥àÍ∏∞ÌôîÎêòÏóàÏäµÎãàÎã§.")
        } else {
            log("API ÌÇ§Í∞Ä's ÎπÑÏñ¥ÏûàÏñ¥ Ï¥àÍ∏∞ÌôîÌï† Ïàò ÏóÜÏäµÎãàÎã§.")
        }
    }
    
    // MARK: - ÏÉà ÎåÄÌôî ÏÑ§Ï†ï
    public func setupNewConversation(model: String, conversationId: String) {
        self.currentModel = model
        self.conversationId = conversationId
        self.currentMessages = []
        log("ÏÉà ÎåÄÌôîÍ∞Ä ÏÑ§Ï†ïÎêòÏóàÏäµÎãàÎã§. Î™®Îç∏: \(model), ID: \(conversationId)")
        objectWillChange.send()
    }
    
    // MARK: - Í∏∞Ï°¥ ÎåÄÌôî ÏÑ§Ï†ï
    func setupExistingConversation(messages: [MessageItem], conversationId: String) {
        self.currentMessages = messages
        self.conversationId = conversationId
        log("Í∏∞Ï°¥ ÎåÄÌôîÍ∞Ä ÏÑ§Ï†ïÎêòÏóàÏäµÎãàÎã§. ID: \(conversationId), Î©îÏãúÏßÄ Ïàò: \(messages.count)")
        objectWillChange.send()
    }
    
    // MARK: - Î©îÏãúÏßÄ Ï†ÑÏÜ°
    public func sendMessage(_ text: String) {
        guard !isProcessing else {
            log("Ïù¥ÎØ∏ Î©îÏãúÏßÄ Ï≤òÎ¶¨ Ï§ëÏûÖÎãàÎã§.")
            return
        }
        
        guard !apiKey.isEmpty else {
            log("API ÌÇ§Í∞Ä ÏÑ§Ï†ïÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§.")
            return
        }
        
        // API Ï¥àÍ∏∞Ìôî ÌôïÏù∏
        initialize()
        
        isProcessing = true
        
        // ÏÇ¨Ïö©Ïûê Î©îÏãúÏßÄ Ï∂îÍ∞Ä
        let userMessage = MessageItem(role: .user, content: text, imageData: nil, timestamp: Date())
        currentMessages.append(userMessage)
        
        // Î©îÏãúÏßÄ ÏóÖÎç∞Ïù¥Ìä∏ ÏΩúÎ∞± Ìò∏Ï∂ú
        onMessagesUpdated?(currentMessages)
        
        // ÏùëÎãµ ÏÉùÏÑ± Ï§ë ÏûÑÏãú Î©îÏãúÏßÄ
        let assistantTypingMessage = MessageItem(role: .model, content: "...", imageData: nil, timestamp: Date())
        currentMessages.append(assistantTypingMessage)
        
        // Î©îÏãúÏßÄ ÏóÖÎç∞Ïù¥Ìä∏ ÏΩúÎ∞± Ìò∏Ï∂ú
        onMessagesUpdated?(currentMessages)
        
        // Gemini API Ìò∏Ï∂ú
        let messages = convertToAPIDicts()
        
        geminiAPI.stream(
            model: currentModel,
            messageDicts: messages,
            tools: [],
            systemPrompt: "",
            onText: { chunk in 
                Task { @MainActor in 
                    self.lastStreamingText = chunk
                    
                    // ÎßàÏßÄÎßâ Î©îÏãúÏßÄ ÏóÖÎç∞Ïù¥Ìä∏
                    if let lastIndex = self.currentMessages.indices.last {
                        self.currentMessages[lastIndex] = MessageItem(
                            role: .model, 
                            content: chunk, 
                            imageData: nil, 
                            timestamp: Date()
                        )
                        
                        // Î©îÏãúÏßÄ ÏóÖÎç∞Ïù¥Ìä∏ ÏΩúÎ∞± Ìò∏Ï∂ú
                        self.onMessagesUpdated?(self.currentMessages)
                    }
                }
            },
            onFunc: { call in 
                Task { @MainActor in 
                    self.log("Ìï®Ïàò Ìò∏Ï∂ú: \(call.name)")
                }
            },
            onDone: { finishReason, error in
                Task { @MainActor in
                    self.isProcessing = false
                    
                    if let error = error {
                        self.log("Ïò§Î•ò Î∞úÏÉù: \(error.localizedDescription)")
                        
                        // Ïò§Î•ò Î©îÏãúÏßÄÎ°ú ÎåÄÏ≤¥
                        if let lastIndex = self.currentMessages.indices.last {
                            self.currentMessages[lastIndex] = MessageItem(
                                role: .model,
                                content: "Î©îÏãúÏßÄ Ï≤òÎ¶¨ Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: \(error.localizedDescription)",
                                imageData: nil,
                                timestamp: Date()
                            )
                            
                            // Î©îÏãúÏßÄ ÏóÖÎç∞Ïù¥Ìä∏ ÏΩúÎ∞± Ìò∏Ï∂ú
                            self.onMessagesUpdated?(self.currentMessages)
                        }
                    } else {
                        self.log("Î©îÏãúÏßÄ Ï≤òÎ¶¨ ÏôÑÎ£å: \(finishReason ?? "unknown")")
                    }
                }
            }
        )
    }
    
    // MARK: - API ÌòïÏãùÏúºÎ°ú Î©îÏãúÏßÄ Î≥ÄÌôò
    private func convertToAPIDicts() -> [[String: Any]] {
        return currentMessages.map { message in
            var dict: [String: Any] = [
                "role": message.role == .user ? "user" : "model",
                "parts": [["text": message.content]]
            ]
            return dict
        }
    }
    
    // MARK: - ÎåÄÌôî ÎÇ¥Î≥¥ÎÇ¥Í∏∞
    func exportConversation() -> [MessageItem] {
        return currentMessages
    }
    
    // MARK: - Message Management
    
    public func setConversation(_ conversation: SoraConversationsDatabase) {
        self.currentConversation = conversation
        self.history = ChatHistoryManager(modelContext: modelContext, conversation: conversation)
        log("ChatService set to work with conversation: \(conversation.title) (ID: \(conversation.id))")
        objectWillChange.send()
    }
    
    public func addUser(
        text   : String,
        image  : UIImage? = nil,
        fileURL: URL?     = nil
    ) {
        guard let history = history else {
            log("Error: ChatHistoryManager not initialized. Call setConversation() first.")
            return
        }
        history.addUser(text: text, image: image, fileURL: fileURL)
        log("User message added to current conversation.")
        objectWillChange.send()
    }
    
    public var messages: [Message] {
        guard let history = history else {
            log("Warning: ChatHistoryManager not initialized. Returning empty messages.")
            return []
        }
        let fetchedMessages = history.messages
        log("Fetched \(fetchedMessages.count) messages for current conversation.")
        return fetchedMessages
    }
    
    // MARK: - LLM Call Entry
    
    public func run(
        model            : String,
        streaming        : Bool = true,
        tools            : [[String: Any]] = [],
        generationConfig : [String: Any]   = [:],
        instructions     : String          = "",
        systemPrompt     : String          = "",
        onUpdate         : @escaping (String)       -> Void,
        onToolCall       : @escaping (ToolCall)     -> Void,
        onDone           : @escaping (String?, Error?) -> Void
    ) {
        guard let history = history, let conversation = currentConversation else {
            log("Error: Conversation not set. Call setConversation() first.")
            onDone(nil, ChatServiceError.conversationNotSet)
            return
        }
        
        lastStreamingText = ""
        
        let provider = ModelProvider.detect(from: model)
        let currentMessages = history.messages
        let dicts = currentMessages.toDicts(provider: provider)
        
        log("‚û°Ô∏è Request: provider=\(provider) model=\(model) id=\(conversation.id)")
        log("   Messages (\(currentMessages.count)): \(dicts)")
        if !tools.isEmpty {
            log("   Tools: \(tools)")
        }
        if provider == .gemini && !systemPrompt.isEmpty {
            log("   systemPrompt: \(systemPrompt)")
        }
        if provider == .openai && !instructions.isEmpty {
            log("   instructions: \(instructions)")
        }
        if !generationConfig.isEmpty {
            log("   generationConfig: \(generationConfig)")
        }
        
        let handleResponse = { [weak self] (responseText: String?, finish: String?, error: Error?) in
            guard let self = self, let history = self.history, let conv = self.currentConversation else { return }
            Task { @MainActor in
                if let text = responseText, !text.isEmpty {
                    let msg = Message(role: "assistant", text: text, conversation: conv)
                    history.append(msg)
                    self.log("Assistant message added: \(text)")
                    self.objectWillChange.send()
                }
                onDone(finish, error)
            }
        }
        
        switch (provider, streaming) {
        case (.gemini, true):
            geminiAPI.stream(
                model        : model,
                messageDicts : dicts,
                tools        : tools,
                systemPrompt : systemPrompt,
                onText       : { chunk in Task { @MainActor in self.lastStreamingText = chunk; onUpdate(chunk); self.log("üîπ Gemini chunk: \(chunk)") } },
                onFunc       : { call in Task { @MainActor in self.log("üîß Gemini func: \(call.name)") } },
                onDone       : { finish, err in handleResponse(self.lastStreamingText, finish, err) }
            )
        case (.gemini, false):
            geminiAPI.generate(
                model         : model,
                messages      : dicts,
                systemPrompt  : systemPrompt,
                generationCfg : generationConfig
            ) { result in
                var resp: String?; var err: Error?; var fin: String? = "stop"
                switch result {
                case .success(let json): resp = LLMResponseParser.textDelta(json, provider: .gemini); onUpdate(resp ?? ""); self.log("‚úÖ Gemini response: \(resp ?? "")")
                case .failure(let e): err = e; fin = nil; self.log("‚ùå Gemini error: \(e.localizedDescription)")
                }
                handleResponse(resp, fin, err)
            }
        case (.openai, true):
            openaiAPI.stream(
                model        : model,
                input        : dicts,
                tools        : tools,
                instructions : instructions,
                onText       : { chunk in Task { @MainActor in self.lastStreamingText = chunk; onUpdate(chunk); self.log("üîπ OpenAI chunk: \(chunk)") } },
                onFunc       : { call in Task { @MainActor in self.log("üîß OpenAI func: \(call.name)") } },
                onDone       : { finish, err in handleResponse(self.lastStreamingText, finish, err) }
            )
        case (.openai, false):
            openaiAPI.generate(
                model        : model,
                input        : dicts,
                instructions : instructions
            ) { result in
                var resp: String?; var err: Error?; var fin: String? = "stop"
                switch result {
                case .success(let json): resp = LLMResponseParser.textDelta(json, provider: .openai); onUpdate(resp ?? ""); self.log("‚úÖ OpenAI response: \(resp ?? "")");
                case .failure(let e): err = e; fin = nil; self.log("‚ùå OpenAI error: \(e.localizedDescription)")
                }
                handleResponse(resp, fin, err)
            }
        }
    }
    
    // MARK: - Logging Helper
    private func log(_ msg: String) {
        let ts = ISO8601DateFormatter().string(from: Date())
        apiLogs.append("[\(ts)] \(msg)")
    }
    
    // MARK: - ChatService Error
    enum ChatServiceError: LocalizedError {
        case conversationNotSet
        
        var errorDescription: String? {
            switch self {
            case .conversationNotSet: return "ChatServiceÏóêÏÑú ÎåÄÌôîÍ∞Ä ÏÑ§Ï†ïÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§. setConversation()Î•º Î®ºÏ†Ä Ìò∏Ï∂úÌï¥Ï£ºÏÑ∏Ïöî."
            }
        }
    }
}
